%
% Copyright © 2012 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%

%
%
%\documentclass{article}

%\input{../peeters_macros.tex}




%\usepackage[bookmarks=true]{hyperref}

\chapter{Notes on shear transformation}
\label{chap:shear}
%\author{Peeter Joot \quad peeterjoot@protonmail.com}
\date{ April 7, 2008.  \(RCSfile: shear.tex,v \) Last \(Revision: 1.10 \) \(Date: 2009/06/14 23:51:45 \) }

%\begin{document}

%\maketitle{}

\section{}

\citep{dorst2007gac} and \citep{doran2003gap}
both give examples of shear transformations of the following
form:

\begin{equation}\label{eqn:shear:20}
F(a) = a + \alpha(a \cdot f) g.
\end{equation}

\citep{doran2003gap}
uses this to compute the determinant without putting the operator in matrix form.  They end up stating that

\begin{equation}\label{eqn:shear:shearblade}
F(A) = A + \alpha (A \cdot f) \wedge g
\end{equation}

holds for any grade blade \(A\).  For grade 1 that is true since

\begin{equation}\label{eqn:shear:40}
\begin{aligned}
(a \cdot f) g
&= \gpgrade{(a \cdot f) g \rangle}{1} \\
&= (a \cdot f) \wedge g.
\end{aligned}
\end{equation}

They demonstrate \eqnref{eqn:shear:shearblade}
holds for the grade 2 case.  To me it seems
like an induction is required to make their statement for any grade.

Question: Is there some other principle that I did not notice in my reading that allows assertion of
\eqnref{eqn:shear:shearblade}
for any grade blade without the induction.

\subsection{Proof for any grade blade}

For \(A \in {\bigwedge}^r\)

\begin{equation}\label{eqn:shear:60}
\begin{aligned}
F(A) \wedge F(b)
&= \left(A + \alpha (A \cdot f) \wedge g \right) \wedge
   \left(b + \alpha(b \cdot f) g \right) \\
&= A \wedge b
 + \alpha
\left(
(A \cdot f) \wedge g \wedge b
+ (b \cdot f) A \wedge g
\right) \\
&= A \wedge b
 + \alpha
\mathLabelBox{
\left(
-(A \cdot f) \wedge b
+ A (b \cdot f)
\right)
}{\(\conj\)}
\wedge g
\\
&= A \wedge b + \alpha ((A \wedge b) \cdot f) \wedge g
\end{aligned}
\end{equation}

QED.

Verification below of \(\conj = f \cdot (A \wedge b)\) is required to complete the proof (can probably find that in one of the books or papers but it is derivable easily enough).

Do I have a sign mixup here somewhere?  Now that I look again I see that GAFP
has the result in different order \((A \cdot f) \wedge g\), and I get negation
reconciling the two.

\subsection{Dot product reduction of blade by one}

\begin{equation}\label{eqn:shear:80}
\begin{aligned}
f \cdot (A \wedge b)
&= \inv{2} \gpgrade{f (A \wedge b)}{r} \\
&= \inv{2} \gpgrade{f (A b + (-1)^r b A)}{r} \\
&= \inv{2} \gpgrade{(f A) b + (-1)^r f b A}{r} \\
&= \inv{2} \gpgrade{((-1)^r A f + 2 f \cdot A) b + (-1)^r f b A}{r} \\
&= (f \cdot A) \wedge b + \frac{(-1)^r}{2} \gpgrade{A f b + f b A}{r} \\
&= (f \cdot A) \wedge b + (-1)^r (f \cdot b) A
+ \frac{(-1)^r}{2} \gpgrade{A f \wedge b + f \wedge b A}{r} \\
\end{aligned}
\end{equation}

This last term, the symmetric product of a bivector with a blade is zero.
The grades \(r-2, r+4, \ldots\) terms are symmetric, and the other grades
\(r, r+4, \ldots\) are antisymmetric.

Thus we have

\begin{equation}
f \cdot (A \wedge b)
= (f \cdot A) \wedge b - (-1)^r (f \cdot b) A
\end{equation}

This generalizes the familiar vector reduction formula to higher grades.
Observe that for the vector case we need the most general definition
of the wedge product for the scalar-vector wedge product (grade \(1-0\) part of the product).

%\bibliographystyle{plainnat} % supposed to allow for \url use.
%\bibliography{myrefs}      % expects file "myrefs.bib"

%\end{document}               % End of document.
